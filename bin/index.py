#!/usr/bin/env python3

# Script used to process a set of geneshot results for visualization in the GLAM Browser
import argparse
import logging
import os
import pandas as pd


def parse_manifest(input_fp):
    """Read in the manifest and filter columns for visualization."""

    # Read the whole manifest
    logging.info("Reading in the manifest")
    manifest = pd.read_hdf(input_fp, "/manifest")
    logging.info("Read in data from {:,} rows and {:,} columns".format(
        manifest.shape[0],
        manifest.shape[1],
    ))

    # Make sure that we have a specimen column
    assert "specimen" in manifest.columns.values

    # Drop any columns with paths to reads
    for k in ["R1", "R2", "I1", "I2"]:
        if k in manifest.columns.values:
            logging.info("Removing column {}".format(k))
            manifest = manifest.drop(columns=k)

    # Drop any columns which do not have unique values for each specimen
    for k in manifest.columns.values:
        if k == "specimen":
            continue
        # Look at just the unique values for this column
        d = manifest.reindex(columns=["specimen", k]).drop_duplicates()
        # Make sure that every specimen has only one value in this column
        if d["specimen"].value_counts().max() > 1:
            logging.info("Removing column with duplicate values: {}".format(k))
            manifest = manifest.drop(columns=k)

    # Now drop duplicates and make sure the specimen column is still unique
    manifest = manifest.drop_duplicates()
    assert manifest["specimen"].value_counts().max() == 1

    # Return the filtered manifest
    return manifest


def index_geneshot_results(input_fp, output_fp):

    # Keep all of the data in a dict linking the key to the table
    dat = {}
    
    # Read in the manifest
    dat["manifest"] = parse_manifest(input_fp)

    # Write out all of the tables to HDF5
    with pd.HDFStore(output_fp, "w") as store:
        for key_name, df in dat.items():
            logging.info("Writing a table with {:,} rows and {:,} columns to {}".format(
                df.shape[0], df.shape[1], output_fp
            ))
            df.to_hdf(
                store,
                key_name
            )


if __name__ == "__main__":

    log_formatter = logging.Formatter(
        "%(asctime)s %(levelname)-8s [GLAM Index] %(message)s"
    )
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)

    # Write logs to STDOUT
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(log_formatter)
    root_logger.addHandler(console_handler)

    parser = argparse.ArgumentParser(
        description="""
        Index a set of geneshot results for visualization with the GLAM Browser.

        Example Usage:

        index.py <INPUT_HDF_FP> <OUTPUT_HDF_FP>

        """
    )

    parser.add_argument(
        "input",
        type=str,
        required=True,
        help="Path to results HDF5 file generated by geneshot"
    )

    parser.add_argument(
        "output",
        type=str,
        required=True,
        help="Path to write out index HDF5 file which can be visualized with the GLAM Browser"
    )

    # Parse the arguments
    args = parser.parse_args()

    # Make sure the input file exists
    assert os.path.exists(args.input), "Cannot find {}".format(args.input)

    # Make sure that the output file does not exist
    assert os.path.exists(args.output) is False, "{} already exists".format(args.output)

    index_geneshot_results(
        args.input,
        args.output
    )
